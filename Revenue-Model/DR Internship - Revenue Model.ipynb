{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebfcd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import seaborn as sns #Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc52265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/lauta/Desktop/Internship DealRoom/data_scientist_intern_revenue_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3362591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>Revenue_2015</th>\n",
       "      <th>Revenue_2016</th>\n",
       "      <th>Revenue_2017</th>\n",
       "      <th>Revenue_2018</th>\n",
       "      <th>Revenue_2019</th>\n",
       "      <th>Employees_2017</th>\n",
       "      <th>Employees_2018</th>\n",
       "      <th>Employees_2019</th>\n",
       "      <th>Employees_2020</th>\n",
       "      <th>Revenue_2020(To predict)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAKI</td>\n",
       "      <td>19,039,781,738</td>\n",
       "      <td>24,671,631,399</td>\n",
       "      <td>24,573,762,847</td>\n",
       "      <td>22,608,855,366</td>\n",
       "      <td>26,574,540,757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YETS</td>\n",
       "      <td>3,687,564,000</td>\n",
       "      <td>3,663,588,000</td>\n",
       "      <td>3,420,430,000</td>\n",
       "      <td>3,265,963,000</td>\n",
       "      <td>3,465,058,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PNMD</td>\n",
       "      <td>3,139,300,000</td>\n",
       "      <td>3,214,000,000</td>\n",
       "      <td>3,196,900,000</td>\n",
       "      <td>3,193,700,000</td>\n",
       "      <td>3,166,000,000</td>\n",
       "      <td>6411.0</td>\n",
       "      <td>6506.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VKNF</td>\n",
       "      <td>1,994,112,000</td>\n",
       "      <td>2,023,348,000</td>\n",
       "      <td>1,982,028,000</td>\n",
       "      <td>2,007,387,000</td>\n",
       "      <td>2,009,031,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HHVD</td>\n",
       "      <td>761,248,939</td>\n",
       "      <td>1,121,284,088</td>\n",
       "      <td>1,245,810,056</td>\n",
       "      <td>1,317,864,838</td>\n",
       "      <td>1,779,401,992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5159.0</td>\n",
       "      <td>5599.0</td>\n",
       "      <td>5483.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OWRH</td>\n",
       "      <td>1,542,346,719</td>\n",
       "      <td>1,432,739,017</td>\n",
       "      <td>1,684,764,846</td>\n",
       "      <td>1,878,176,166</td>\n",
       "      <td>1,756,472,782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DQVE</td>\n",
       "      <td>1,198,734,028</td>\n",
       "      <td>1,377,446,067</td>\n",
       "      <td>1,461,826,444</td>\n",
       "      <td>1,657,818,945</td>\n",
       "      <td>1,663,037,290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3405.0</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>3096.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMBV</td>\n",
       "      <td>1,423,357,300</td>\n",
       "      <td>1,455,164,329</td>\n",
       "      <td>1,406,572,220</td>\n",
       "      <td>1,534,895,751</td>\n",
       "      <td>1,667,789,302</td>\n",
       "      <td>197.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LLQC</td>\n",
       "      <td>1,462,664,130</td>\n",
       "      <td>1,343,274,474</td>\n",
       "      <td>1,487,356,029</td>\n",
       "      <td>1,562,650,199</td>\n",
       "      <td>1,575,028,199</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>3748.0</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XXEK</td>\n",
       "      <td>1,592,032,000</td>\n",
       "      <td>1,585,729,000</td>\n",
       "      <td>1,476,923,000</td>\n",
       "      <td>1,451,335,000</td>\n",
       "      <td>1,513,090,000</td>\n",
       "      <td>389.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME   Revenue_2015     Revenue_2016    Revenue_2017    Revenue_2018  \\\n",
       "0  LAKI  19,039,781,738  24,671,631,399  24,573,762,847  22,608,855,366   \n",
       "1  YETS   3,687,564,000   3,663,588,000   3,420,430,000   3,265,963,000   \n",
       "2  PNMD   3,139,300,000   3,214,000,000   3,196,900,000   3,193,700,000   \n",
       "3  VKNF   1,994,112,000   2,023,348,000   1,982,028,000   2,007,387,000   \n",
       "4  HHVD     761,248,939   1,121,284,088   1,245,810,056   1,317,864,838   \n",
       "5  OWRH   1,542,346,719   1,432,739,017   1,684,764,846   1,878,176,166   \n",
       "6  DQVE   1,198,734,028   1,377,446,067   1,461,826,444   1,657,818,945   \n",
       "7  SMBV   1,423,357,300   1,455,164,329   1,406,572,220   1,534,895,751   \n",
       "8  LLQC   1,462,664,130   1,343,274,474   1,487,356,029   1,562,650,199   \n",
       "9  XXEK   1,592,032,000   1,585,729,000   1,476,923,000   1,451,335,000   \n",
       "\n",
       "     Revenue_2019  Employees_2017  Employees_2018  Employees_2019  \\\n",
       "0  26,574,540,757             NaN           805.0           790.0   \n",
       "1   3,465,058,000             NaN          2394.0          2494.0   \n",
       "2   3,166,000,000          6411.0          6506.0          7750.0   \n",
       "3   2,009,031,000             NaN          1925.0          1995.0   \n",
       "4   1,779,401,992             NaN          5159.0          5599.0   \n",
       "5   1,756,472,782             NaN           319.0           343.0   \n",
       "6   1,663,037,290             NaN          3405.0          3377.0   \n",
       "7   1,667,789,302           197.0           203.0           209.0   \n",
       "8   1,575,028,199          3492.0          3748.0          3845.0   \n",
       "9   1,513,090,000           389.0           425.0           442.0   \n",
       "\n",
       "   Employees_2020  Revenue_2020(To predict)  \n",
       "0           785.0                       NaN  \n",
       "1          2548.0                       NaN  \n",
       "2             NaN                       NaN  \n",
       "3          2050.0                       NaN  \n",
       "4          5483.0                       NaN  \n",
       "5           335.0                       NaN  \n",
       "6          3096.0                       NaN  \n",
       "7             NaN                       NaN  \n",
       "8             NaN                       NaN  \n",
       "9             NaN                       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dd3b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17424 entries, 0 to 17423\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   NAME                      17424 non-null  object \n",
      " 1   Revenue_2015              10483 non-null  object \n",
      " 2   Revenue_2016              11737 non-null  object \n",
      " 3   Revenue_2017              12531 non-null  object \n",
      " 4   Revenue_2018              13576 non-null  object \n",
      " 5   Revenue_2019              10245 non-null  object \n",
      " 6   Employees_2017            2180 non-null   float64\n",
      " 7   Employees_2018            5844 non-null   float64\n",
      " 8   Employees_2019            13135 non-null  float64\n",
      " 9   Employees_2020            9725 non-null   float64\n",
      " 10  Revenue_2020(To predict)  0 non-null      float64\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Checking general info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de01af1",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae589b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unncessary column\n",
    "df.pop('Revenue_2020(To predict)')\n",
    "\n",
    "#Correcting the names of the columns\n",
    "df.rename(columns = {'Revenue_2015 ': 'Revenue_2015'}, inplace=True)\n",
    "\n",
    "#Correcting the format of missing information in the dataset\n",
    "df.replace(' -   ', np.nan, inplace=True)\n",
    "\n",
    "#Taking out the ',' to convert into numeric columns\n",
    "df[\"Revenue_2015\"] = df[\"Revenue_2015\"].str.replace(',', '')\n",
    "df[\"Revenue_2016\"] = df[\"Revenue_2016\"].str.replace(',', '')\n",
    "df[\"Revenue_2017\"] = df[\"Revenue_2017\"].str.replace(',', '')\n",
    "df[\"Revenue_2018\"] = df[\"Revenue_2018\"].str.replace(',', '')\n",
    "df[\"Revenue_2019\"] = df[\"Revenue_2019\"].str.replace(',', '')\n",
    "\n",
    "#Converting revenue columns into numeric to proccess them\n",
    "df[\"Revenue_2015\"] = pd.to_numeric(df[\"Revenue_2015\"])\n",
    "df[\"Revenue_2016\"] = pd.to_numeric(df[\"Revenue_2016\"])\n",
    "df[\"Revenue_2017\"] = pd.to_numeric(df[\"Revenue_2017\"])\n",
    "df[\"Revenue_2018\"] = pd.to_numeric(df[\"Revenue_2018\"])\n",
    "df[\"Revenue_2019\"] = pd.to_numeric(df[\"Revenue_2019\"])\n",
    "\n",
    "#I noticed some data appeared as '1' when in fact it seems that it was supposed to be a NA value. Here I corrected this.\n",
    "df['Revenue_2015'].values[df['Revenue_2015'] == 1] = np.nan\n",
    "df['Revenue_2016'].values[df['Revenue_2016'] == 1] = np.nan\n",
    "df['Revenue_2017'].values[df['Revenue_2017'] == 1] = np.nan\n",
    "df['Revenue_2018'].values[df['Revenue_2018'] == 1] = np.nan\n",
    "df['Revenue_2019'].values[df['Revenue_2019'] == 1] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73380f",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204b4814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue_2015</th>\n",
       "      <th>Revenue_2016</th>\n",
       "      <th>Revenue_2017</th>\n",
       "      <th>Revenue_2018</th>\n",
       "      <th>Revenue_2019</th>\n",
       "      <th>Employees_2017</th>\n",
       "      <th>Employees_2018</th>\n",
       "      <th>Employees_2019</th>\n",
       "      <th>Employees_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Revenue_2015</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975891</td>\n",
       "      <td>0.970413</td>\n",
       "      <td>0.948331</td>\n",
       "      <td>0.956856</td>\n",
       "      <td>0.486929</td>\n",
       "      <td>0.078318</td>\n",
       "      <td>0.084387</td>\n",
       "      <td>0.070315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Revenue_2016</th>\n",
       "      <td>0.975891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991962</td>\n",
       "      <td>0.962105</td>\n",
       "      <td>0.961430</td>\n",
       "      <td>0.503408</td>\n",
       "      <td>0.101678</td>\n",
       "      <td>0.109150</td>\n",
       "      <td>0.093010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Revenue_2017</th>\n",
       "      <td>0.970413</td>\n",
       "      <td>0.991962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983793</td>\n",
       "      <td>0.978679</td>\n",
       "      <td>0.544048</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>0.117551</td>\n",
       "      <td>0.100618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Revenue_2018</th>\n",
       "      <td>0.948331</td>\n",
       "      <td>0.962105</td>\n",
       "      <td>0.983793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993628</td>\n",
       "      <td>0.514907</td>\n",
       "      <td>0.114797</td>\n",
       "      <td>0.123631</td>\n",
       "      <td>0.108384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Revenue_2019</th>\n",
       "      <td>0.956856</td>\n",
       "      <td>0.961430</td>\n",
       "      <td>0.978679</td>\n",
       "      <td>0.993628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528004</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.150134</td>\n",
       "      <td>0.128557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employees_2017</th>\n",
       "      <td>0.486929</td>\n",
       "      <td>0.503408</td>\n",
       "      <td>0.544048</td>\n",
       "      <td>0.514907</td>\n",
       "      <td>0.528004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994442</td>\n",
       "      <td>0.986724</td>\n",
       "      <td>0.966659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employees_2018</th>\n",
       "      <td>0.078318</td>\n",
       "      <td>0.101678</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>0.114797</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.994442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.999186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employees_2019</th>\n",
       "      <td>0.084387</td>\n",
       "      <td>0.109150</td>\n",
       "      <td>0.117551</td>\n",
       "      <td>0.123631</td>\n",
       "      <td>0.150134</td>\n",
       "      <td>0.986724</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employees_2020</th>\n",
       "      <td>0.070315</td>\n",
       "      <td>0.093010</td>\n",
       "      <td>0.100618</td>\n",
       "      <td>0.108384</td>\n",
       "      <td>0.128557</td>\n",
       "      <td>0.966659</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Revenue_2015  Revenue_2016  Revenue_2017  Revenue_2018  \\\n",
       "Revenue_2015        1.000000      0.975891      0.970413      0.948331   \n",
       "Revenue_2016        0.975891      1.000000      0.991962      0.962105   \n",
       "Revenue_2017        0.970413      0.991962      1.000000      0.983793   \n",
       "Revenue_2018        0.948331      0.962105      0.983793      1.000000   \n",
       "Revenue_2019        0.956856      0.961430      0.978679      0.993628   \n",
       "Employees_2017      0.486929      0.503408      0.544048      0.514907   \n",
       "Employees_2018      0.078318      0.101678      0.109343      0.114797   \n",
       "Employees_2019      0.084387      0.109150      0.117551      0.123631   \n",
       "Employees_2020      0.070315      0.093010      0.100618      0.108384   \n",
       "\n",
       "                Revenue_2019  Employees_2017  Employees_2018  Employees_2019  \\\n",
       "Revenue_2015        0.956856        0.486929        0.078318        0.084387   \n",
       "Revenue_2016        0.961430        0.503408        0.101678        0.109150   \n",
       "Revenue_2017        0.978679        0.544048        0.109343        0.117551   \n",
       "Revenue_2018        0.993628        0.514907        0.114797        0.123631   \n",
       "Revenue_2019        1.000000        0.528004        0.138917        0.150134   \n",
       "Employees_2017      0.528004        1.000000        0.994442        0.986724   \n",
       "Employees_2018      0.138917        0.994442        1.000000        0.999710   \n",
       "Employees_2019      0.150134        0.986724        0.999710        1.000000   \n",
       "Employees_2020      0.128557        0.966659        0.999186        0.999786   \n",
       "\n",
       "                Employees_2020  \n",
       "Revenue_2015          0.070315  \n",
       "Revenue_2016          0.093010  \n",
       "Revenue_2017          0.100618  \n",
       "Revenue_2018          0.108384  \n",
       "Revenue_2019          0.128557  \n",
       "Employees_2017        0.966659  \n",
       "Employees_2018        0.999186  \n",
       "Employees_2019        0.999786  \n",
       "Employees_2020        1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8256f",
   "metadata": {},
   "source": [
    "We can see high correlatios between Revenues from each years and other years, \n",
    "and between quantities of employees from each year to other years but not so much in between this two types of variables\n",
    "We can also see that the closer the year is (e.g. 2018 is closer to 2019 than 2016) the higher the correlation between variables\n",
    "\n",
    "Nevertheless, the amount of missing data seems to be a challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edb805c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME              0.00\n",
       "Revenue_2015      0.41\n",
       "Revenue_2016      0.34\n",
       "Revenue_2017      0.29\n",
       "Revenue_2018      0.23\n",
       "Revenue_2019      0.42\n",
       "Employees_2017    0.87\n",
       "Employees_2018    0.66\n",
       "Employees_2019    0.25\n",
       "Employees_2020    0.44\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking percetanges of missing data per column\n",
    "round(df.isnull().mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eeac4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quatity of Companies that we don't have any data about past revenues: 177\n"
     ]
    }
   ],
   "source": [
    "#Getting the Quantity of observations who are missing all data about past revenues\n",
    "print(\"Quatity of Companies that we don't have any data about past revenues: \" + str(len(df[df.iloc[:,1:6].isnull().sum(1)==5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ea645",
   "metadata": {},
   "source": [
    "#### Predictions on this companies' revenue would be very inaccurate given that the only data that we have is Quantity of Employees from past years and this not enough. But I will proceed to include their predictions given the nature of this excercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c22236",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32570030",
   "metadata": {},
   "source": [
    "There are multiple ways to deal with missing data. In this case, given that there's a high linear correlation between the same types of variables from different years, I decided to use one of the most robust methods, which is the Multiple Imputation. However, the imputations will be done only on the basis of the high related variables (i.e. the revenue of a missing year will be imputed by the predictions of the revenue of others years but not on the quantity of employees).\n",
    "\n",
    "Although this method if very robust, because of lack of data a lot of imputations will be just the mean of the variable. Furthermore, this will create an overstimation of the linear correlation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b0e41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues = ['Revenue_2015','Revenue_2016','Revenue_2017','Revenue_2018','Revenue_2019']\n",
    "employees = ['Employees_2017','Employees_2018','Employees_2019', 'Employees_2020']\n",
    "\n",
    "df_revenues = df[revenues]\n",
    "df_employees = df[employees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9760a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "imputer = IterativeImputer(estimator = lr, max_iter=30)\n",
    "\n",
    "df[revenues] = imputer.fit_transform(df_revenues)\n",
    "\n",
    "imputer = IterativeImputer(estimator = lr, max_iter=30, min_value=0)\n",
    "\n",
    "\n",
    "df[employees] = imputer.fit_transform(df_employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003a689",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a232470e",
   "metadata": {},
   "source": [
    "#### For the predicting task, I decided to use the last 4 years of revenues of each company and the current quantity of employees as features. First, I made a dataset for the year 2019 to use as training set and one for 2020 to use as the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea9c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'-4 Year' : df.Revenue_2015, '-3 Year': df.Revenue_2016, '-2 Year': df.Revenue_2017, '-1 Year': df.Revenue_2018, 'Employees': df.Employees_2019, 'Target': df.Revenue_2019})\n",
    "test = pd.DataFrame({'-4 Year' : df.Revenue_2016, '-3 Year': df.Revenue_2017, '-2 Year': df.Revenue_2018, '-1 Year': df.Revenue_2019, 'Employees': df.Employees_2020})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de44fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splittin the training set into train and validation sets\n",
    "train, validation = train_test_split(df_train, \n",
    "                                     train_size = 0.8, \n",
    "                                     test_size = 0.2,\n",
    "                                    random_state=7)\n",
    "\n",
    "y_train = train.pop('Target')\n",
    "X_train = train\n",
    "\n",
    "y_validation = validation.pop('Target')\n",
    "X_validation = validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fbb5762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Mean R2 Score for Training set with 5 Splits:  0.97\n",
      "Cross Validation Mean MAE Score for Training set with 5 Splits:  3296073.56\n"
     ]
    }
   ],
   "source": [
    "#Getting the scores from cross validation of the training set\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 7)\n",
    "r2_scores = cross_val_score(lr, X_train, y_train, scoring='r2', cv=folds)\n",
    "mae_scores = cross_val_score(lr, X_train, y_train, scoring='neg_mean_absolute_error', cv=folds)\n",
    "\n",
    "print('Cross Validation Mean R2 Score for Training set with 5 Splits: ', round(np.mean(r2_scores),2))\n",
    "print('Cross Validation Mean MAE Score for Training set with 5 Splits: ', round(np.mean(abs(mae_scores)),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5482a37b",
   "metadata": {},
   "source": [
    "#### The Mean of the 5 Fold Cross R2 Score Validation with a linear regression model is very high, meaning that the total variance of the target variable is almost completey explained by the dependent variables. The difference that a complex model (like neural networks) could bring to the accuracy would not be worth the explainability that this model has. For this reason, I decided to use the linear regression as the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16ce9770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score is:  0.99\n",
      "Mean Squared Error:  2651602.96\n"
     ]
    }
   ],
   "source": [
    "#Definite score of the validation set\n",
    "model = lr.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_validation)\n",
    "r2 = sklearn.metrics.r2_score(y_validation, y_pred)\n",
    "mse = mean_absolute_error(y_validation, y_pred)\n",
    "print('R2 Score is: ' , round(r2,2))\n",
    "print('Mean Squared Error: ', round(mse,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3818a",
   "metadata": {},
   "source": [
    "#### Here we can see that the predictions from 2019 with this model miss the actual value on average by 2651602.96. We should expect that prediction for 2020 will have a similar or bigger error in each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e868f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the predictions on the testset (Revenue of 2020)\n",
    "df['Revenue_2020'] = model.predict(test)\n",
    "df.to_csv(\"C:/Users/lauta/Desktop/Internship DealRoom/revenue_model_complete.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
