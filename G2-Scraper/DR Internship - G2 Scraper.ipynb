{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f34a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0398aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/lauta/Desktop/Internship DealRoom/data_scientist_intern_G2_scraper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dacdac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NAME</th>\n",
       "      <th>WEBSITE</th>\n",
       "      <th>TAGLINE</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>INDUSTRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1773270</td>\n",
       "      <td>Matera (formerly illiCopros)</td>\n",
       "      <td>https://www.matera.eu/</td>\n",
       "      <td>Allows residential property owners to self-man...</td>\n",
       "      <td>12 Rue du 4 septembre, 75002 Paris, France</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1659999</td>\n",
       "      <td>Shift</td>\n",
       "      <td>https://shift.online/</td>\n",
       "      <td>Move Anything, Anywhere, Anytime</td>\n",
       "      <td>40 Islington High St, Islington, London N1</td>\n",
       "      <td>travel;transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1617238</td>\n",
       "      <td>MILES Mobility</td>\n",
       "      <td>https://miles-mobility.com/</td>\n",
       "      <td>An independent carsharing and modern mobility</td>\n",
       "      <td>Leibnizstraße 49, 10629 Berlin, Germany</td>\n",
       "      <td>transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1519744</td>\n",
       "      <td>Doktor24</td>\n",
       "      <td>https://doktor24.se</td>\n",
       "      <td>Leading the digitalization of Swedish primary ...</td>\n",
       "      <td>Birger Jarlsgatan, Stockholm, Sweden</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975908</td>\n",
       "      <td>Forecast</td>\n",
       "      <td>https://www.forecast.app</td>\n",
       "      <td>AI-powered resource &amp; project management platform</td>\n",
       "      <td>20, Frederiksborggade, 1360 Copenhagen, Denmark</td>\n",
       "      <td>enterprise software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                          NAME                      WEBSITE  \\\n",
       "0  1773270  Matera (formerly illiCopros)       https://www.matera.eu/   \n",
       "1  1659999                         Shift        https://shift.online/   \n",
       "2  1617238                MILES Mobility  https://miles-mobility.com/   \n",
       "3  1519744                      Doktor24          https://doktor24.se   \n",
       "4   975908                      Forecast     https://www.forecast.app   \n",
       "\n",
       "                                             TAGLINE  \\\n",
       "0  Allows residential property owners to self-man...   \n",
       "1                   Move Anything, Anywhere, Anytime   \n",
       "2      An independent carsharing and modern mobility   \n",
       "3  Leading the digitalization of Swedish primary ...   \n",
       "4  AI-powered resource & project management platform   \n",
       "\n",
       "                                           ADDRESS             INDUSTRIES  \n",
       "0       12 Rue du 4 septembre, 75002 Paris, France            real estate  \n",
       "1       40 Islington High St, Islington, London N1  travel;transportation  \n",
       "2          Leibnizstraße 49, 10629 Berlin, Germany         transportation  \n",
       "3             Birger Jarlsgatan, Stockholm, Sweden                 health  \n",
       "4  20, Frederiksborggade, 1360 Copenhagen, Denmark    enterprise software  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c743b",
   "metadata": {},
   "source": [
    "#### Clean names of the companies to use them as search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f81dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_parenthesis = []\n",
    "no_commas = []\n",
    "for name in df.NAME[df.NAME.str.contains('(', regex=False)].str.split('('):\n",
    "    no_parenthesis.append(name[0])\n",
    "    \n",
    "for name in df.NAME[df.NAME.str.contains(',', regex=False)].str.split(','):\n",
    "    no_commas.append(name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b79286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NAME[df.NAME.str.contains('(', regex=False)] = no_parenthesis\n",
    "df.NAME[df.NAME.str.contains(',', regex=False)] = no_commas\n",
    "df.NAME = df.NAME.str.strip()\n",
    "df.NAME = df.NAME.str.replace(' ', '+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c67c1",
   "metadata": {},
   "source": [
    "#### G2 Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f3c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions() \n",
    "options.add_argument(\"start-maximized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6eba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped at :  Spaceos Index:  11\n"
     ]
    }
   ],
   "source": [
    "g2_webs = []\n",
    "ratings = []\n",
    "reviews = []\n",
    "product_descriptions = []\n",
    "alternatives = []\n",
    "\n",
    "#Initialize chrome bot\n",
    "driver = uc.Chrome(options=options)\n",
    "#Go to G2 web page so we can accept cookies\n",
    "driver.get('https://www.g2.com/')\n",
    "time.sleep(3)\n",
    "#Accept cookies\n",
    "driver.find_element_by_xpath('//*[@id=\"new_user_consent\"]/input[6]').click()\n",
    "\n",
    "#for every company there's in the dataset\n",
    "for i in range(0,len(df)):\n",
    "    #use the name of the company to do a query on G2\n",
    "    driver.get('https://www.g2.com/search?utf8=%E2%9C%93&query=' + df.NAME[i])     \n",
    "\n",
    "    #if found a captcha, break the loop and print at  which company it stopped to scrap\n",
    "    if len(driver.find_elements_by_class_name('challenge-form.interactive-form')) ==1:\n",
    "        print('Stopped at : ', df.NAME[i], 'Index: ',i)\n",
    "        break\n",
    "    #if the search result is 0 (meaning G2 has no info on that company), then append \"No info\" for this company    \n",
    "    elif len(driver.find_elements_by_class_name('product-listing__head')) == 0 :\n",
    "        g2_web = 'No info'\n",
    "        rating = 'No info'\n",
    "        review ='No info'\n",
    "        product_description = 'No info'\n",
    "        alterna = 'No info'\n",
    "        time.sleep(3)\n",
    "              \n",
    "    else:\n",
    "        #if there's at least one result, then loop over clicking on each of the results and compare the website listed to\n",
    "        #the one in the dataset to see if we're dealing with the same company\n",
    "        for found in range(0,len(driver.find_elements_by_class_name('d-ib.c-midnight-100.js-log-click'))):\n",
    "            driver.find_elements_by_class_name('d-ib.c-midnight-100.js-log-click')[found].click()\n",
    "            \n",
    "            try:\n",
    "                element1 = driver.find_element_by_class_name('p-1.border-top')\n",
    "            except:\n",
    "                element1 = driver.find_element_by_class_name('p-1')\n",
    "            if element1.find_element_by_class_name('link').get_attribute('href')  != df.WEBSITE[i]:\n",
    "                driver.execute_script(\"window.history.go(-1)\")\n",
    "                \n",
    "                #if none of the first 5 results from the query has the same webpage from the company in the dataset, \n",
    "                #then append \"no info\"\n",
    "                if (found+1 == len(driver.find_elements_by_class_name('d-ib.c-midnight-100.js-log-click'))) or (found == 4):\n",
    "                    g2_web = 'No info'\n",
    "                    rating = 'No info'\n",
    "                    review = 'No info'\n",
    "                    product_description = 'No info'\n",
    "                    alterna = 'No info'\n",
    "                    time.sleep(3)\n",
    "            #if there's a hit (same website in the dataset and in G2 listing) proceed to get info\n",
    "            else:\n",
    "                #if this company has reviews\n",
    "                g2_web = driver.current_url\n",
    "                if len(driver.find_elements_by_class_name('f-3')) > 0:\n",
    "                    five_stars = int(driver.find_elements_by_class_name('f-3')[0].text)\n",
    "                    four_stars = int(driver.find_elements_by_class_name('f-3')[1].text)\n",
    "                    three_stars = int(driver.find_elements_by_class_name('f-3')[2].text)\n",
    "                    two_stars = int(driver.find_elements_by_class_name('f-3')[3].text)\n",
    "                    one_stars = int(driver.find_elements_by_class_name('f-3')[4].text)\n",
    "\n",
    "                    rating = ((five_stars * 5) + (four_stars * 4) + (three_stars * 3) + (two_stars * 2) + one_stars) / (five_stars + four_stars + three_stars + two_stars + one_stars)\n",
    "                    review = five_stars + four_stars + three_stars + two_stars + one_stars\n",
    "                else:\n",
    "                    #if there's no review yet on this company, just append \"no info\"\n",
    "                    rating = 'No info'\n",
    "                    review = 'No info'\n",
    "                #get the elements equivalent to the info needed\n",
    "                product_description = driver.find_elements_by_class_name('ws-pw')[0].text\n",
    "                alterna = []\n",
    "                for alternative in range(0,5):\n",
    "                    alterna.append(driver.find_elements_by_class_name('module-heading.row-list-item-title.gray.ellipsis')[alternative].text)\n",
    "                break\n",
    "    #append the info obtained from the company to the list\n",
    "    g2_webs.append(g2_web)\n",
    "    ratings.append(rating)\n",
    "    reviews.append(review)\n",
    "    product_descriptions.append(product_description)\n",
    "    alternatives.append(alterna)\n",
    "    time.sleep(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3084220",
   "metadata": {},
   "source": [
    "#### We add the results scraped to the original dataset. Neverhteless, G2 kept blocking the bot, so I figured it wasnt worth to save results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['G2 Web'] = g2_webs\n",
    "df['Rating'] = ratings\n",
    "df['N Reviews'] = reviews\n",
    "df['Description'] = product_descriptions\n",
    "df['Alternatives'] = alternatives\n",
    "\n",
    "df.to_csv('Complete_Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8ee84",
   "metadata": {},
   "source": [
    "#### It would be possible to scrap the entire dataset keeping the results we can get into a short dataset, and resume in big intervals of time within the last result found, but it would take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2318a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                      1786924\n",
       "NAME                                                    Spaceos\n",
       "WEBSITE                                     https://spaceos.io/\n",
       "TAGLINE       Offers a smart, simple and intuitive web and m...\n",
       "ADDRESS       Krakowskie Przedmieście 13, 00-071 Warszawa, P...\n",
       "INDUSTRIES                                          real estate\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[11]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
